{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac32b381",
   "metadata": {},
   "source": [
    "# Rock Paper Scissors Classification \n",
    "\n",
    "This notebook ensures consistent and correct class label ordering by explicitly sorting class folders alphabetically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b1f94e",
   "metadata": {},
   "source": [
    "## 1. Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb052c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install datasets --quiet\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad058920",
   "metadata": {},
   "source": [
    "## 2. Extract Dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05bf5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_dataset(\"Javtor/rock-paper-scissors\")\n",
    "label_names = dataset['train'].features['label'].names\n",
    "\n",
    "base_dir = \"dataset\"\n",
    "splits = ['train', 'test']\n",
    "\n",
    "def save_images_to_folder(split_name):\n",
    "    split_dataset = dataset[split_name]\n",
    "    for idx, sample in enumerate(split_dataset):\n",
    "        label = label_names[sample['label']]\n",
    "        image = sample['image']\n",
    "        if image.mode == 'RGBA':\n",
    "            image = image.convert('RGB')\n",
    "        save_dir = os.path.join(base_dir, split_name, label)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        image_path = os.path.join(save_dir, f\"{split_name}_{label}_{idx}.jpg\")\n",
    "        image.save(image_path)\n",
    "\n",
    "for split in splits:\n",
    "    save_images_to_folder(split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4e473",
   "metadata": {},
   "source": [
    "## 3. Enforce Alphabetical Class Label Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dir = 'dataset/train'\n",
    "class_names = sorted(os.listdir(train_dir))  # ['paper', 'rock', 'scissors']\n",
    "print(\"âœ… Sorted class names used for prediction:\", class_names)\n",
    "\n",
    "with open(\"class_names.json\", \"w\") as f:\n",
    "    json.dump(class_names, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232db41",
   "metadata": {},
   "source": [
    "## 4. Create Augmented Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    validation_split=0.2\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=(224, 224), batch_size=32,\n",
    "    class_mode='categorical', subset='training'\n",
    ")\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=(224, 224), batch_size=32,\n",
    "    class_mode='categorical', subset='validation'\n",
    ")\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    'dataset/test', target_size=(224, 224), batch_size=32, class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dcdeca",
   "metadata": {},
   "source": [
    "## 5. Compute Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30835e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = train_gen.classes\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd490c37",
   "metadata": {},
   "source": [
    "## 6. Define and Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e428416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(train_gen.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e064c9",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(train_gen, validation_data=val_gen,\n",
    "                    epochs=10, class_weight=class_weights, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7cad67",
   "metadata": {},
   "source": [
    "## 8. Fine-Tune Last 20 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "fine_tune_history = model.fit(train_gen, validation_data=val_gen,\n",
    "                              epochs=5, class_weight=class_weights, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfaf063",
   "metadata": {},
   "source": [
    "## 9. Plot Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed = []\n",
    "    for point in points:\n",
    "        if smoothed:\n",
    "            smoothed.append(smoothed[-1] * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed.append(point)\n",
    "    return smoothed\n",
    "\n",
    "def combine_history(h1, h2):\n",
    "    combined = {}\n",
    "    for k in h1.history:\n",
    "        combined[k] = h1.history[k] + h2.history.get(k, [])\n",
    "    return combined\n",
    "\n",
    "full_history = combine_history(history, fine_tune_history)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(smooth_curve(full_history['accuracy']), label='Training Acc')\n",
    "plt.plot(smooth_curve(full_history['val_accuracy']), label='Val Acc')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(smooth_curve(full_history['loss']), label='Training Loss')\n",
    "plt.plot(smooth_curve(full_history['val_loss']), label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1044fd",
   "metadata": {},
   "source": [
    "## 10. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ac32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(\"rock_paper_scissors_model.h5\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(\"rock_paper_scissors_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
